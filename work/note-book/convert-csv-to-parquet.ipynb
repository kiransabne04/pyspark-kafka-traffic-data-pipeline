{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ddc1be9-9537-4bba-ba37-320e5b3de4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/spark/python (3.5.0)\n",
      "Collecting py4j==0.10.9.7 (from pyspark)\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: py4j\n",
      "Successfully installed py4j-0.10.9.7\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a42b3d3d-b3e6-4aa6-9dd1-2e179a0d7d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d27089a1-d6d7-416c-bd5c-826402007e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .appName(\"convert-csv-parquet\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20e559fb-3c03-4eb1-83c1-5c4d032e7074",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"work/output/data\"\n",
    "output_dir = \"work/output/parquet\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a28c419-0ea8-4a89-8f65-9fef11c29a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = [f for f in os.listdir(input_dir) if f.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0921e068-7b43-4f97-af77-9c72fd9488e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chunk_0.csv', 'chunk_1.csv', 'chunk_10.csv', 'chunk_2.csv', 'chunk_3.csv', 'chunk_4.csv', 'chunk_5.csv', 'chunk_6.csv', 'chunk_7.csv', 'chunk_8.csv', 'chunk_9.csv']\n"
     ]
    }
   ],
   "source": [
    "print(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5acd5ee-b8f5-4b22-ad75-b606e8dc07e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted chunk_0.csv to work/output/parquet/chunk_0.parquet\n",
      "converted chunk_1.csv to work/output/parquet/chunk_1.parquet\n",
      "converted chunk_10.csv to work/output/parquet/chunk_10.parquet\n",
      "converted chunk_2.csv to work/output/parquet/chunk_2.parquet\n",
      "converted chunk_3.csv to work/output/parquet/chunk_3.parquet\n",
      "converted chunk_4.csv to work/output/parquet/chunk_4.parquet\n",
      "converted chunk_5.csv to work/output/parquet/chunk_5.parquet\n",
      "converted chunk_6.csv to work/output/parquet/chunk_6.parquet\n",
      "converted chunk_7.csv to work/output/parquet/chunk_7.parquet\n",
      "converted chunk_8.csv to work/output/parquet/chunk_8.parquet\n",
      "converted chunk_9.csv to work/output/parquet/chunk_9.parquet\n",
      "all CSV files have been converted to parquet format.\n"
     ]
    }
   ],
   "source": [
    "for csv_file in csv_files:\n",
    "    csv_file_path = os.path.join(input_dir, csv_file)\n",
    "    df = spark.read.format(\"csv\").option(\"header\", \"true\").load(csv_file_path)\n",
    "\n",
    "    parquet_file_path = os.path.join(output_dir, csv_file.replace('.csv', '.parquet'))\n",
    "\n",
    "    df.write.mode(\"overwrite\").parquet(parquet_file_path)\n",
    "\n",
    "    print(f\"converted {csv_file} to {parquet_file_path}\")\n",
    "\n",
    "print(\"all CSV files have been converted to parquet format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70834e96-fd7a-4c01-95e6-8b52de028a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f5670a-a158-4e2a-b806-aa4a7f30e874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
